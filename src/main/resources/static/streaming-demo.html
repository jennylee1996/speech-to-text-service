<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AssemblyAI Real-time Streaming Demo</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        .controls {
            display: flex;
            gap: 10px;
        }
        button {
            padding: 10px 15px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        button:disabled {
            background-color: #cccccc;
        }
        .transcript {
            min-height: 200px;
            border: 1px solid #ddd;
            padding: 15px;
            border-radius: 4px;
            background-color: #f9f9f9;
        }
        .status {
            font-style: italic;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>AssemblyAI Real-time Streaming Demo</h1>
        
        <div class="status" id="status">Ready to start</div>
        
        <div class="controls">
            <button id="startBtn">Start Recording</button>
            <button id="stopBtn" disabled>Stop Recording</button>
        </div>
        
        <div class="transcript" id="transcript"></div>
    </div>

    <script>
        // DOM elements
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusEl = document.getElementById('status');
        const transcriptEl = document.getElementById('transcript');
        
        // Variables
        let mediaRecorder;
        let audioChunks = [];
        let sessionId = null;
        let eventSource = null;
        
        // Set up button event listeners
        startBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', stopRecording);
        
        async function startRecording() {
            try {
                // Clear previous transcript
                transcriptEl.textContent = '';
                
                // Start a new session
                statusEl.textContent = 'Starting session...';
                const sessionResponse = await fetch('/api/streaming/start', {
                    method: 'POST'
                });
                
                if (!sessionResponse.ok) {
                    throw new Error('Failed to start session');
                }
                
                const sessionData = await sessionResponse.json();
                sessionId = sessionData.sessionId;
                
                // Set up event source for real-time updates
                setupEventSource();
                
                // Request microphone access
                statusEl.textContent = 'Requesting microphone access...';
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Set up media recorder
                mediaRecorder = new MediaRecorder(stream);
                
                mediaRecorder.addEventListener('dataavailable', async event => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                        
                        // Convert to base64 and send to server
                        const audioBlob = new Blob([event.data], { type: 'audio/webm' });
                        const reader = new FileReader();
                        reader.readAsDataURL(audioBlob);
                        reader.onloadend = async () => {
                            const base64Audio = reader.result.split(',')[1]; // Remove data URL prefix
                            
                            try {
                                await fetch('/api/streaming/transcribe', {
                                    method: 'POST',
                                    headers: {
                                        'Content-Type': 'application/json'
                                    },
                                    body: JSON.stringify({
                                        sessionId: sessionId,
                                        audioChunk: base64Audio,
                                        languageCode: 'en'
                                    })
                                });
                            } catch (error) {
                                console.error('Error sending audio chunk:', error);
                            }
                        };
                    }
                });
                
                // Start recording
                mediaRecorder.start(1000); // Send data every 1 second
                
                // Update UI
                statusEl.textContent = 'Recording...';
                startBtn.disabled = true;
                stopBtn.disabled = false;
            } catch (error) {
                console.error('Error starting recording:', error);
                statusEl.textContent = 'Error: ' + error.message;
            }
        }
        
        function setupEventSource() {
            // Close any existing event source
            if (eventSource) {
                eventSource.close();
            }
            
            // Set up a new event source
            eventSource = new EventSource(`/api/streaming/events?sessionId=${sessionId}`);
            
            eventSource.onmessage = event => {
                try {
                    const data = JSON.parse(event.data);
                    if (data.messageType === 'PartialTranscript') {
                        // Update transcript with partial result
                        transcriptEl.textContent = data.text;
                    } else if (data.messageType === 'FinalTranscript') {
                        // Update transcript with final result
                        transcriptEl.textContent = data.text;
                    } else if (data.messageType === 'Error') {
                        statusEl.textContent = 'Error: ' + data.error;
                    }
                } catch (error) {
                    console.error('Error parsing event data:', error);
                }
            };
            
            eventSource.onerror = error => {
                console.error('EventSource error:', error);
                eventSource.close();
            };
        }
        
        async function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                
                // Stop all audio tracks
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                // Clear resources
                audioChunks = [];
                mediaRecorder = null;
                
                // End the session
                try {
                    await fetch(`/api/streaming/end?sessionId=${sessionId}`, {
                        method: 'POST'
                    });
                } catch (error) {
                    console.error('Error ending session:', error);
                }
                
                // Close event source
                if (eventSource) {
                    eventSource.close();
                    eventSource = null;
                }
                
                // Update UI
                statusEl.textContent = 'Recording stopped';
                startBtn.disabled = false;
                stopBtn.disabled = true;
            }
        }
    </script>
</body>
</html> 